{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "## Theano\n",
    "\n",
    "  * Python library that provides efficient (low-level) tools for working with Neural Networks\n",
    "  * In particular:\n",
    "      * Automatic Differentiation (AD)\n",
    "      * Compiled computation graphs\n",
    "      * GPU accelerated computation\n",
    "\n",
    "## Keras\n",
    "\n",
    "   * High level library for specifying and training neural networks\n",
    "   * Can use `Theano` or `TensorFlow` as backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "  * 70,000 handwritten digits\n",
    "      * 60,000 for training\n",
    "      * 10,000 for testing\n",
    "  * As 28x28 pixel images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "  * implement layer-by-layer training in the Stacked Autoencoder\n",
    "  * implement supervised fine tuning on pre-trained \"Autoencoder\"\n",
    "  * implement filter visualisation by gradient ascent on neuron activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the data\n",
    "\n",
    "Let's load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(images_train, labels_train), (images_test, labels_test) = mnist.load_data()\n",
    "print('images',images_train.shape)\n",
    "print('labels', labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then visualise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_mnist_digit(image, figsize=None):\n",
    "    \"\"\" Plot a single MNIST image.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    if figsize:\n",
    "        ax.set_figsize(*figsize)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_1_by_2_images(image, reconstruction, figsize=None):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.matshow(reconstruction, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_10_by_10_images(images, figsize=None):\n",
    "    \"\"\" Plot 100 MNIST images in a 10 by 10 table. Note that we crop\n",
    "    the images so that they appear reasonably close together.  The\n",
    "    image is post-processed to give the appearance of being continued.\"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    #images = [image[3:25, 3:25] for image in images]\n",
    "    #image = np.concatenate(images, axis=1)\n",
    "    for x in range(10):\n",
    "        for y in range(10):\n",
    "            ax = fig.add_subplot(10, 10, 10*y+x+1)\n",
    "            ax.matshow(images[10*y+x], cmap = matplotlib.cm.binary)\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_image(i):\n",
    "    plot_mnist_digit(images_train[i])\n",
    "    print(i, ':', labels_train[i])\n",
    "interact(draw_image, i=(0, len(images_train)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_10_by_10_images(images_train, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_features(X):\n",
    "    return X.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "\n",
    "def to_images(X):\n",
    "    return (X*255.0).astype('uint8').reshape(-1, 28, 28)\n",
    "\n",
    "print((images_train[0]-(to_images(to_features(images_train[0])))).max())\n",
    "print('data shape:', images_train.shape)\n",
    "print('features shape', to_features(images_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "X_train = to_features(images_train)\n",
    "X_test = to_features(images_test)\n",
    "print(X_train.shape, 'training samples')\n",
    "print(X_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels we transform to a \"one-hot\" encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The labels need to be transformed into class indicators\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(labels_train, nb_classes=10)\n",
    "y_test = np_utils.to_categorical(labels_test, nb_classes=10)\n",
    "print(y_train.shape, 'train labels')\n",
    "print(y_test.shape, 'test labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's inspect the first 3 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('labels', labels_train[:3])\n",
    "print('y', y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Multi-Layer Perceptron (MLP)\n",
    "\n",
    "The simplest kind of Artificial Neural Network is as Multi-Layer Perceptron (MLP) with a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Architecture Parameters\n",
    "nb_input = 784\n",
    "nb_hidden = 512\n",
    "nb_output = 10\n",
    "# Training Parameters\n",
    "nb_epoch = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the \"architecture\" of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(output_dim=nb_hidden, input_dim=nb_input, init='uniform'))\n",
    "mlp.add(Activation('sigmoid'))\n",
    "mlp.add(Dense(output_dim=nb_output, input_dim=nb_hidden, init='uniform'))\n",
    "mlp.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we compile it. This takes the symbolic computational graph of the model and compiles it an efficient implementation which can then be used to train and evaluate the model. \n",
    "\n",
    "Note that we have to specify what loss/objective function we want to use as well which optimisation algorithm to use. **SGD** stands for Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the model on our training data. Watch the loss, which is the objective function which we are minimising, and the estimated accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train, \n",
    "        batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "        verbose=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we can evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.evaluate(X_test, y_test, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_mlp_prediction(j):\n",
    "    plot_mnist_digit(to_images(X_test)[j])\n",
    "    prediction = mlp.predict_classes(X_test[j:j+1], verbose=False)[0]\n",
    "    print(j, ':', '\\tpredict:', prediction, '\\tactual:', labels_test[j])\n",
    "interact(draw_mlp_prediction, j=(0, len(X_test)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_10_by_10_images(images_test, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deeper MLP\n",
    "\n",
    "Next we build a two-layer MLP with the same number of hidden nodes, half in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "nb_layers = 1\n",
    "mlp2 = Sequential()\n",
    "# add hidden layers\n",
    "for i in range(nb_layers):\n",
    "    mlp2.add(Dense(output_dim=nb_hidden/nb_layers, input_dim=nb_input if i==0 else nb_hidden/nb_layers, init='uniform'))\n",
    "    mlp2.add(Activation('sigmoid'))\n",
    "# add output layer\n",
    "mlp2.add(Dense(output_dim=nb_output, input_dim=nb_hidden/nb_layers, init='uniform'))\n",
    "mlp2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp2.compile(loss='categorical_crossentropy', optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp2.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp2.evaluate(X_test, y_test, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Manual Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "mae = Sequential()\n",
    "nb_layers = 1\n",
    "encoder = []\n",
    "decoder = []\n",
    "for i in range(nb_layers):\n",
    "    if i>0:\n",
    "        encoder.append(Dropout(0.4))\n",
    "    encoder.append(Dense(output_dim=nb_hidden/nb_layers,\n",
    "                         input_dim=nb_input if i==0 else nb_hidden/nb_layers,\n",
    "                         init='glorot_uniform'))\n",
    "    encoder.append(Activation('sigmoid'))\n",
    "    \n",
    "    # Note that these are in reverse order\n",
    "    decoder.append(Activation('sigmoid'))\n",
    "    decoder.append(Dense(output_dim=nb_input if i==0 else nb_hidden/nb_layers,\n",
    "                         input_dim=nb_hidden/nb_layers,\n",
    "                         init='glorot_uniform'))\n",
    "    #decoder.append(Dropout(0.2))\n",
    "\n",
    "for layer in encoder:\n",
    "    mae.add(layer)\n",
    "for layer in reversed(decoder):\n",
    "    mae.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mae.compile(loss='mse', optimizer='SGD')  # replace with sgd, 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mae.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_mae_prediction(j):\n",
    "    X_plot = X_test[j:j+1]\n",
    "    prediction = mae.predict(X_plot, verbose=False)\n",
    "    plot_1_by_2_images(to_images(X_plot)[0], to_images(prediction)[0])\n",
    "interact(draw_mae_prediction, j=(0, len(X_test)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_10_by_10_images(images_test, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "class StackedAutoencoder(object):\n",
    "    \n",
    "    def __init__(self, layers, mode='autoencoder',\n",
    "                 activation='sigmoid', init='uniform', final_activation='softmax',\n",
    "                 dropout=0.2, optimizer='SGD'):\n",
    "        self.layers = layers\n",
    "        self.mode = mode\n",
    "        self.activation = activation\n",
    "        self.final_activation = final_activation\n",
    "        self.init = init\n",
    "        self.dropout = dropout\n",
    "        self.optimizer = optimizer\n",
    "        self._model = None\n",
    "        \n",
    "        self.build()\n",
    "        self.compile()\n",
    "    \n",
    "    def _add_layer(self, model, i, is_encoder):\n",
    "        if is_encoder:\n",
    "            input_dim, output_dim = self.layers[i], self.layers[i+1]\n",
    "            activation = self.final_activation if i==len(self.layers)-2 else self.activation\n",
    "        else:\n",
    "            input_dim, output_dim = self.layers[i+1], self.layers[i]\n",
    "            activation = self.activation\n",
    "        model.add(Dense(output_dim=output_dim,\n",
    "                        input_dim=input_dim,\n",
    "                        init=self.init))\n",
    "        model.add(Activation(activation))\n",
    "        \n",
    "    def build(self):\n",
    "        self.encoder = Sequential()\n",
    "        self.decoder = Sequential()\n",
    "        self.autoencoder = Sequential()\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self._add_layer(self.encoder, i, True)\n",
    "            self._add_layer(self.autoencoder, i, True)\n",
    "            #if i<len(self.layers)-2:\n",
    "            #    self.autoencoder.add(Dropout(self.dropout))\n",
    "\n",
    "        # Note that the decoder layers are in reverse order\n",
    "        for i in reversed(range(len(self.layers)-1)):\n",
    "            self._add_layer(self.decoder, i, False)\n",
    "            self._add_layer(self.autoencoder, i, False)\n",
    "            \n",
    "    def compile(self):\n",
    "        print(\"Compiling the encoder ...\")\n",
    "        self.encoder.compile(loss='categorical_crossentropy', optimizer=self.optimizer)\n",
    "        print(\"Compiling the decoder ...\")\n",
    "        self.decoder.compile(loss='mse', optimizer=self.optimizer)\n",
    "        print(\"Compiling the autoencoder ...\")\n",
    "        return self.autoencoder.compile(loss='mse', optimizer=self.optimizer)\n",
    "    \n",
    "    def fit(self, X_train, Y_train, batch_size, nb_epoch, verbose=1):\n",
    "        result = self.autoencoder.fit(X_train, Y_train,\n",
    "                                      batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                                      verbose=verbose)\n",
    "        # copy the weights to the encoder\n",
    "        for i, l in enumerate(self.encoder.layers):\n",
    "            l.set_weights(self.autoencoder.layers[i].get_weights())\n",
    "        for i in range(len(self.decoder.layers)):\n",
    "            self.decoder.layers[-1-i].set_weights(self.autoencoder.layers[-1-i].get_weights())\n",
    "        return result\n",
    "    \n",
    "    def pretrain(self, X_train, batch_size, nb_epoch, verbose=1):\n",
    "        for i in range(len(self.layers)-1):\n",
    "            # Greedily train each layer\n",
    "            print(\"Now pretraining layer {} [{}-->{}]\".format(i+1, self.layers[i], self.layers[i+1]))\n",
    "            ae = Sequential()\n",
    "            self._add_layer(ae, i, True)\n",
    "            #ae.add(Dropout(self.dropout))\n",
    "            self._add_layer(ae, i, False)\n",
    "            ae.compile(loss='mse', optimizer=self.optimizer)\n",
    "            ae.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose)\n",
    "            # Then lift the training data up one layer\n",
    "            print(\"Transforming ouput from\", X_train.shape)\n",
    "            enc = Sequential()\n",
    "            self._add_layer(enc, i, True)\n",
    "            enc.compile(loss='mse', optimizer=self.optimizer)\n",
    "            enc.layers[0].set_weights(ae.layers[0].get_weights())\n",
    "            enc.layers[1].set_weights(ae.layers[1].get_weights())\n",
    "            X_train = enc.predict(X_train, verbose=verbose)\n",
    "            print(\"to\", X_train.shape)\n",
    "            # Then copy the learned weights\n",
    "            self.encoder.layers[2*i].set_weights(ae.layers[0].get_weights())\n",
    "            self.encoder.layers[2*i+1].set_weights(ae.layers[1].get_weights())\n",
    "            self.autoencoder.layers[2*i].set_weights(ae.layers[0].get_weights())\n",
    "            self.autoencoder.layers[2*i+1].set_weights(ae.layers[1].get_weights())\n",
    "            self.decoder.layers[-1-(2*i)].set_weights(ae.layers[-1].get_weights())\n",
    "            self.decoder.layers[-1-(2*i+1)].set_weights(ae.layers[-2].get_weights())\n",
    "            self.autoencoder.layers[-1-(2*i)].set_weights(ae.layers[-1].get_weights())\n",
    "            self.autoencoder.layers[-1-(2*i+1)].set_weights(ae.layers[-2].get_weights())\n",
    "            \n",
    "    \n",
    "    def evaluate(self, X_test, Y_test, show_accuracy=False):\n",
    "        return self.autoencoder.evaluate(X_test, Y_test, show_accuracy=show_accuracy)\n",
    "    \n",
    "    def predict(self, X, verbose=False):\n",
    "        return self.autoencoder.predict(X, verbose=verbose)\n",
    "\n",
    "    def _get_paths(self, name):\n",
    "        model_path = \"models/{}_model.yaml\".format(name)\n",
    "        weights_path = \"models/{}_weights.hdf5\".format(name)\n",
    "        return model_path, weights_path\n",
    "\n",
    "    def save(self, name='autoencoder'):\n",
    "        model_path, weights_path = self._get_paths(name)\n",
    "        open(model_path, 'w').write(self.autoencoder.to_yaml())\n",
    "        self.autoencoder.save_weights(weights_path, overwrite=True)\n",
    "    \n",
    "    def load(self, name='autoencoder'):\n",
    "        model_path, weights_path = self._get_paths(name)\n",
    "        self.autoencoder = keras.models.model_from_yaml(open(model_path))\n",
    "        self.autoencoder.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sae = StackedAutoencoder(layers=[nb_input, 500, 100, 25, 10],\n",
    "                         activation='sigmoid',\n",
    "                         final_activation='sigmoid',\n",
    "                         init='uniform',\n",
    "                         dropout=0.2,\n",
    "                         optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sae.pretrain(X_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sae.compile()\n",
    "sae.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_sae_prediction(j):\n",
    "    X_plot = X_test[j:j+1]\n",
    "    prediction = sae.predict(X_plot, verbose=False)\n",
    "    plot_1_by_2_images(to_images(X_plot)[0], to_images(prediction)[0])\n",
    "    print(sae.encoder.predict(X_plot, verbose=False)[0])\n",
    "interact(draw_sae_prediction, j=(0, len(X_test)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_10_by_10_images(images_test, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sae.evaluate(X_test, X_test, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise_filter(model, layer_index, filter_index):\n",
    "    from keras import backend as K\n",
    "\n",
    "    # build a loss function that maximizes the activation\n",
    "    # of the nth filter on the layer considered\n",
    "    layer_output = model.layers[layer_index].get_output()\n",
    "    loss = K.mean(layer_output[:, filter_index])\n",
    "\n",
    "    # compute the gradient of the input picture wrt this loss\n",
    "    input_img = model.layers[0].input\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # we start from a gray image with some noise\n",
    "    input_img_data = np.random.random((1,nb_input,))\n",
    "    # run gradient ascent for 20 steps\n",
    "    step = 1\n",
    "    for i in range(100):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        #print(\"Current loss value:\", loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "    print(\"Current loss value:\", loss_value)\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value>0:\n",
    "        #return input_img_data[0]\n",
    "        return input_img_data\n",
    "    else:\n",
    "        raise ValueError(loss_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_filter(i):\n",
    "    flt = visualise_filter(mlp, 3, 4)\n",
    "    #print(flt)\n",
    "    plot_mnist_digit(to_images(flt)[0])\n",
    "interact(draw_filter, i=[0, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions that I have\n",
    "\n",
    "  * How often are the Dropout neurons reset? Once an epoch or more often?\n",
    "  * Is Dropout removed during the predict() call?\n",
    "  * Should inputs be centered on zero for Dropout to be appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
