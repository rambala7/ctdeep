{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Train a simple deep NN on the MNIST dataset.\n",
    "Get to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mnist_digit(image, figsize=None):\n",
    "    \"\"\" Plot a single MNIST image.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    if figsize:\n",
    "        ax.set_figsize(*figsize)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_train))\n",
    "plot_mnist_digit(X_train[i])\n",
    "print(i, ':', y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_10_by_10_images(images, figsize=None):\n",
    "    \"\"\" Plot 100 MNIST images in a 10 by 10 table. Note that we crop\n",
    "    the images so that they appear reasonably close together.  The\n",
    "    image is post-processed to give the appearance of being continued.\"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    #images = [image[3:25, 3:25] for image in images]\n",
    "    #image = np.concatenate(images, axis=1)\n",
    "    for x in range(10):\n",
    "        for y in range(10):\n",
    "            ax = fig.add_subplot(10, 10, 10*y+x+1)\n",
    "            ax.matshow(images[10*y+x], cmap = matplotlib.cm.binary)\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "    plt.show()\n",
    "    \n",
    "plot_10_by_10_images(X_train, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The labels need to be transformed into class indicators\n",
    "from keras.utils import np_utils\n",
    "nb_classes = 10\n",
    "y_train_cat = np_utils.to_categorical(y_train, nb_classes=nb_classes)\n",
    "y_test_cat = np_utils.to_categorical(y_test, nb_classes=nb_classes)\n",
    "print(y_train_cat.shape, 'train labels')\n",
    "print(y_test_cat.shape, 'test labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(output_dim=64, input_dim=784, init='uniform'))\n",
    "mlp.add(Activation('sigmoid'))\n",
    "mlp.add(Dense(output_dim=nb_classes, input_dim=64, init='uniform'))\n",
    "mlp.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp.compile(loss='categorical_crossentropy', optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train_cat, batch_size=32, nb_epoch=10, verbose=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.evaluate(X_test, y_test_cat, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = np.random.randint(len(X_test))\n",
    "plot_mnist_digit(X_test[j].reshape(28,28))\n",
    "prediction = mlp.predict_classes(X_test[j:j+1], verbose=False)[0]\n",
    "print(j, ':', prediction, y_test[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating the autoencoder\n",
    "ae = Sequential()\n",
    "encoder = containers.Sequential()\n",
    "encoder.add(Dense(input_dim=784, output_dim=20, init='uniform'))\n",
    "encoder.add(Activation('relu'))\n",
    "decoder = containers.Sequential()\n",
    "decoder.add(Dense(20, 784, init='uniform'))\n",
    "decoder.add(Activation('relu'))\n",
    "ae.add(AutoEncoder(encoder=encoder, decoder=decoder,\n",
    "                   output_reconstruction=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae.compile(loss='mean_squared_error', optimizer=SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "       show_accuracy=True, verbose=1, validation_data=[X_test, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
